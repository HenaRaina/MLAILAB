{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Questions_Internal_R6_AIML_Labs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUZjPnVXGz0Z",
        "colab_type": "text"
      },
      "source": [
        "# The Iris Dataset\n",
        "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
        "\n",
        "The dataset contains a set of 150 records under five attributes - petal length, petal width, sepal length, sepal width and species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOk8Eu4_t70R",
        "colab_type": "text"
      },
      "source": [
        "Firstly, let's select TensorFlow version 2.x in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6RZUm0p4wYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9763e1ed-8c50-44d8-ce5d-c58041d9d0a4"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRHsCk67XYjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0398e83e-149c-4a60-9872-abdd7f3244a7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print (tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWi96z-8SyX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-vVQBBqg7DI",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE0EDKvQhEIe",
        "colab_type": "text"
      },
      "source": [
        "### Import dataset\n",
        "- Import iris dataset\n",
        "- Import the dataset using sklearn library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOOWpD26Haq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pandas \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta8YqInTh5v5",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HERt3drbhX0i",
        "colab_type": "text"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- you can get the features using .data method\n",
        "- you can get the features using .target method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cV-_qHAHyvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg1A2lkUjFak",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state: 1\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYKNJL85h7pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data up in train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0KVP17Ozaix",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADY1ZLL9e7-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41027766-0244-43d9-b511-6108b36bc77c"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIjqxbhWv1zv",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encode the labels\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert labels\n",
        "- number of classes: 3\n",
        "- we are doing this to use categorical_crossentropy as loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9vv-_gpyLY9",
        "colab": {}
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=3, dtype='float32')\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=3, dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovjLyYzWkO9s"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbIFzoPNSyYo",
        "colab_type": "text"
      },
      "source": [
        "### Initialize a sequential model\n",
        "- Define a sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FvSbf1UjHtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.layers.advanced_activations import ReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dGMy999vlacX"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ibK5Jxm8iL",
        "colab_type": "text"
      },
      "source": [
        "### Add a layer\n",
        "- Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3\n",
        "- Apply Softmax on Dense Layer outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZKrBNSRm_o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the constructor\n",
        "model = Sequential()\n",
        "\n",
        "# Add an input layer \n",
        "model.add(Dense(8, activation='relu', input_shape=(4,)))\n",
        "\n",
        "# Add an output layer \n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4uiTH8plmNX",
        "colab_type": "text"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJL8n8vcSyYz",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "- Use SGD as Optimizer\n",
        "- Use categorical_crossentropy as loss function\n",
        "- Use accuracy as metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc_-fjIEk1ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sihIGbRll_jT"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ZZCfNGlu0i",
        "colab_type": "text"
      },
      "source": [
        "### Summarize the model\n",
        "- Check model layers\n",
        "- Understand number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elER3F_4ln8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4d83c451-066a-49b5-af8d-27d725ab9d09"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 8)                 40        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 67\n",
            "Trainable params: 67\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2PiP7j3Vmj4p"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWdbfFCXmCHt",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "- Give train data as training features and labels\n",
        "- Epochs: 100\n",
        "- Give validation data as testing features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO1c-5tjmBVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "epochs = 100\n",
        "batch_size = 112"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re9ItAR3yS3J",
        "colab_type": "text"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liw0IFf9yVqH",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions\n",
        "- Predict labels on one row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5sBybi6mlLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fad428ea-41f9-471d-e924-eaa9086d31dd"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.3, verbose=True)\n",
        "loss,accuracy  = model.evaluate(X_test, y_test, verbose=False)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 78 samples, validate on 34 samples\n",
            "Epoch 1/100\n",
            "78/78 [==============================] - 0s 4ms/sample - loss: 1.5972 - accuracy: 0.3205 - val_loss: 1.2160 - val_accuracy: 0.4118\n",
            "Epoch 2/100\n",
            "78/78 [==============================] - 0s 147us/sample - loss: 1.4507 - accuracy: 0.3205 - val_loss: 1.1561 - val_accuracy: 0.4118\n",
            "Epoch 3/100\n",
            "78/78 [==============================] - 0s 167us/sample - loss: 1.3640 - accuracy: 0.3205 - val_loss: 1.1246 - val_accuracy: 0.4706\n",
            "Epoch 4/100\n",
            "78/78 [==============================] - 0s 159us/sample - loss: 1.3066 - accuracy: 0.3590 - val_loss: 1.1052 - val_accuracy: 0.6176\n",
            "Epoch 5/100\n",
            "78/78 [==============================] - 0s 128us/sample - loss: 1.2635 - accuracy: 0.5256 - val_loss: 1.0911 - val_accuracy: 0.5882\n",
            "Epoch 6/100\n",
            "78/78 [==============================] - 0s 143us/sample - loss: 1.2285 - accuracy: 0.4487 - val_loss: 1.0799 - val_accuracy: 0.4412\n",
            "Epoch 7/100\n",
            "78/78 [==============================] - 0s 142us/sample - loss: 1.1989 - accuracy: 0.3462 - val_loss: 1.0703 - val_accuracy: 0.4118\n",
            "Epoch 8/100\n",
            "78/78 [==============================] - 0s 137us/sample - loss: 1.1731 - accuracy: 0.3333 - val_loss: 1.0621 - val_accuracy: 0.3824\n",
            "Epoch 9/100\n",
            "78/78 [==============================] - 0s 142us/sample - loss: 1.1502 - accuracy: 0.3205 - val_loss: 1.0541 - val_accuracy: 0.3824\n",
            "Epoch 10/100\n",
            "78/78 [==============================] - 0s 152us/sample - loss: 1.1296 - accuracy: 0.3205 - val_loss: 1.0463 - val_accuracy: 0.3824\n",
            "Epoch 11/100\n",
            "78/78 [==============================] - 0s 154us/sample - loss: 1.1108 - accuracy: 0.3205 - val_loss: 1.0382 - val_accuracy: 0.3824\n",
            "Epoch 12/100\n",
            "78/78 [==============================] - 0s 141us/sample - loss: 1.0933 - accuracy: 0.3205 - val_loss: 1.0299 - val_accuracy: 0.3824\n",
            "Epoch 13/100\n",
            "78/78 [==============================] - 0s 152us/sample - loss: 1.0771 - accuracy: 0.3205 - val_loss: 1.0212 - val_accuracy: 0.3824\n",
            "Epoch 14/100\n",
            "78/78 [==============================] - 0s 144us/sample - loss: 1.0622 - accuracy: 0.3205 - val_loss: 1.0119 - val_accuracy: 0.3824\n",
            "Epoch 15/100\n",
            "78/78 [==============================] - 0s 151us/sample - loss: 1.0473 - accuracy: 0.3205 - val_loss: 1.0021 - val_accuracy: 0.3824\n",
            "Epoch 16/100\n",
            "78/78 [==============================] - 0s 163us/sample - loss: 1.0336 - accuracy: 0.3205 - val_loss: 0.9908 - val_accuracy: 0.3824\n",
            "Epoch 17/100\n",
            "78/78 [==============================] - 0s 184us/sample - loss: 1.0200 - accuracy: 0.3205 - val_loss: 0.9802 - val_accuracy: 0.4118\n",
            "Epoch 18/100\n",
            "78/78 [==============================] - 0s 199us/sample - loss: 1.0088 - accuracy: 0.3205 - val_loss: 0.9688 - val_accuracy: 0.4118\n",
            "Epoch 19/100\n",
            "78/78 [==============================] - 0s 178us/sample - loss: 0.9977 - accuracy: 0.3333 - val_loss: 0.9592 - val_accuracy: 0.4118\n",
            "Epoch 20/100\n",
            "78/78 [==============================] - 0s 182us/sample - loss: 0.9875 - accuracy: 0.3333 - val_loss: 0.9518 - val_accuracy: 0.4118\n",
            "Epoch 21/100\n",
            "78/78 [==============================] - 0s 221us/sample - loss: 0.9794 - accuracy: 0.3333 - val_loss: 0.9450 - val_accuracy: 0.4118\n",
            "Epoch 22/100\n",
            "78/78 [==============================] - 0s 172us/sample - loss: 0.9719 - accuracy: 0.3462 - val_loss: 0.9396 - val_accuracy: 0.4118\n",
            "Epoch 23/100\n",
            "78/78 [==============================] - 0s 158us/sample - loss: 0.9651 - accuracy: 0.3462 - val_loss: 0.9348 - val_accuracy: 0.4118\n",
            "Epoch 24/100\n",
            "78/78 [==============================] - 0s 211us/sample - loss: 0.9585 - accuracy: 0.3462 - val_loss: 0.9301 - val_accuracy: 0.4118\n",
            "Epoch 25/100\n",
            "78/78 [==============================] - 0s 180us/sample - loss: 0.9522 - accuracy: 0.3462 - val_loss: 0.9259 - val_accuracy: 0.4118\n",
            "Epoch 26/100\n",
            "78/78 [==============================] - 0s 191us/sample - loss: 0.9462 - accuracy: 0.3590 - val_loss: 0.9218 - val_accuracy: 0.4118\n",
            "Epoch 27/100\n",
            "78/78 [==============================] - 0s 175us/sample - loss: 0.9405 - accuracy: 0.3590 - val_loss: 0.9180 - val_accuracy: 0.4118\n",
            "Epoch 28/100\n",
            "78/78 [==============================] - 0s 185us/sample - loss: 0.9350 - accuracy: 0.3590 - val_loss: 0.9142 - val_accuracy: 0.4118\n",
            "Epoch 29/100\n",
            "78/78 [==============================] - 0s 188us/sample - loss: 0.9296 - accuracy: 0.3590 - val_loss: 0.9105 - val_accuracy: 0.4118\n",
            "Epoch 30/100\n",
            "78/78 [==============================] - 0s 164us/sample - loss: 0.9244 - accuracy: 0.3590 - val_loss: 0.9068 - val_accuracy: 0.4118\n",
            "Epoch 31/100\n",
            "78/78 [==============================] - 0s 174us/sample - loss: 0.9192 - accuracy: 0.3718 - val_loss: 0.9031 - val_accuracy: 0.4118\n",
            "Epoch 32/100\n",
            "78/78 [==============================] - 0s 190us/sample - loss: 0.9140 - accuracy: 0.4103 - val_loss: 0.8994 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "78/78 [==============================] - 0s 134us/sample - loss: 0.9089 - accuracy: 0.4615 - val_loss: 0.8958 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "78/78 [==============================] - 0s 241us/sample - loss: 0.9039 - accuracy: 0.5385 - val_loss: 0.8921 - val_accuracy: 0.5294\n",
            "Epoch 35/100\n",
            "78/78 [==============================] - 0s 134us/sample - loss: 0.8989 - accuracy: 0.5897 - val_loss: 0.8885 - val_accuracy: 0.5588\n",
            "Epoch 36/100\n",
            "78/78 [==============================] - 0s 154us/sample - loss: 0.8939 - accuracy: 0.6410 - val_loss: 0.8849 - val_accuracy: 0.5588\n",
            "Epoch 37/100\n",
            "78/78 [==============================] - 0s 170us/sample - loss: 0.8890 - accuracy: 0.6795 - val_loss: 0.8813 - val_accuracy: 0.5588\n",
            "Epoch 38/100\n",
            "78/78 [==============================] - 0s 172us/sample - loss: 0.8842 - accuracy: 0.7051 - val_loss: 0.8778 - val_accuracy: 0.5882\n",
            "Epoch 39/100\n",
            "78/78 [==============================] - 0s 158us/sample - loss: 0.8794 - accuracy: 0.7308 - val_loss: 0.8743 - val_accuracy: 0.6471\n",
            "Epoch 40/100\n",
            "78/78 [==============================] - 0s 163us/sample - loss: 0.8747 - accuracy: 0.7436 - val_loss: 0.8708 - val_accuracy: 0.6765\n",
            "Epoch 41/100\n",
            "78/78 [==============================] - 0s 153us/sample - loss: 0.8700 - accuracy: 0.7564 - val_loss: 0.8674 - val_accuracy: 0.6765\n",
            "Epoch 42/100\n",
            "78/78 [==============================] - 0s 185us/sample - loss: 0.8654 - accuracy: 0.7564 - val_loss: 0.8639 - val_accuracy: 0.6765\n",
            "Epoch 43/100\n",
            "78/78 [==============================] - 0s 162us/sample - loss: 0.8608 - accuracy: 0.7564 - val_loss: 0.8605 - val_accuracy: 0.6765\n",
            "Epoch 44/100\n",
            "78/78 [==============================] - 0s 132us/sample - loss: 0.8562 - accuracy: 0.7564 - val_loss: 0.8571 - val_accuracy: 0.6765\n",
            "Epoch 45/100\n",
            "78/78 [==============================] - 0s 139us/sample - loss: 0.8517 - accuracy: 0.7692 - val_loss: 0.8537 - val_accuracy: 0.6765\n",
            "Epoch 46/100\n",
            "78/78 [==============================] - 0s 165us/sample - loss: 0.8472 - accuracy: 0.7821 - val_loss: 0.8504 - val_accuracy: 0.7059\n",
            "Epoch 47/100\n",
            "78/78 [==============================] - 0s 270us/sample - loss: 0.8428 - accuracy: 0.7949 - val_loss: 0.8471 - val_accuracy: 0.7059\n",
            "Epoch 48/100\n",
            "78/78 [==============================] - 0s 166us/sample - loss: 0.8384 - accuracy: 0.7949 - val_loss: 0.8438 - val_accuracy: 0.7059\n",
            "Epoch 49/100\n",
            "78/78 [==============================] - 0s 179us/sample - loss: 0.8340 - accuracy: 0.7949 - val_loss: 0.8405 - val_accuracy: 0.7353\n",
            "Epoch 50/100\n",
            "78/78 [==============================] - 0s 277us/sample - loss: 0.8297 - accuracy: 0.7949 - val_loss: 0.8373 - val_accuracy: 0.7353\n",
            "Epoch 51/100\n",
            "78/78 [==============================] - 0s 161us/sample - loss: 0.8254 - accuracy: 0.7949 - val_loss: 0.8341 - val_accuracy: 0.7353\n",
            "Epoch 52/100\n",
            "78/78 [==============================] - 0s 145us/sample - loss: 0.8212 - accuracy: 0.7949 - val_loss: 0.8309 - val_accuracy: 0.7353\n",
            "Epoch 53/100\n",
            "78/78 [==============================] - 0s 154us/sample - loss: 0.8170 - accuracy: 0.7949 - val_loss: 0.8277 - val_accuracy: 0.7353\n",
            "Epoch 54/100\n",
            "78/78 [==============================] - 0s 171us/sample - loss: 0.8128 - accuracy: 0.7949 - val_loss: 0.8246 - val_accuracy: 0.7353\n",
            "Epoch 55/100\n",
            "78/78 [==============================] - 0s 164us/sample - loss: 0.8087 - accuracy: 0.7949 - val_loss: 0.8214 - val_accuracy: 0.7353\n",
            "Epoch 56/100\n",
            "78/78 [==============================] - 0s 171us/sample - loss: 0.8046 - accuracy: 0.7949 - val_loss: 0.8183 - val_accuracy: 0.7353\n",
            "Epoch 57/100\n",
            "78/78 [==============================] - 0s 173us/sample - loss: 0.8005 - accuracy: 0.7949 - val_loss: 0.8152 - val_accuracy: 0.7647\n",
            "Epoch 58/100\n",
            "78/78 [==============================] - 0s 164us/sample - loss: 0.7965 - accuracy: 0.7949 - val_loss: 0.8121 - val_accuracy: 0.7647\n",
            "Epoch 59/100\n",
            "78/78 [==============================] - 0s 196us/sample - loss: 0.7925 - accuracy: 0.7949 - val_loss: 0.8091 - val_accuracy: 0.7647\n",
            "Epoch 60/100\n",
            "78/78 [==============================] - 0s 197us/sample - loss: 0.7885 - accuracy: 0.7949 - val_loss: 0.8061 - val_accuracy: 0.7941\n",
            "Epoch 61/100\n",
            "78/78 [==============================] - 0s 232us/sample - loss: 0.7846 - accuracy: 0.7949 - val_loss: 0.8031 - val_accuracy: 0.7941\n",
            "Epoch 62/100\n",
            "78/78 [==============================] - 0s 167us/sample - loss: 0.7807 - accuracy: 0.7949 - val_loss: 0.8001 - val_accuracy: 0.7941\n",
            "Epoch 63/100\n",
            "78/78 [==============================] - 0s 159us/sample - loss: 0.7769 - accuracy: 0.7949 - val_loss: 0.7971 - val_accuracy: 0.7941\n",
            "Epoch 64/100\n",
            "78/78 [==============================] - 0s 200us/sample - loss: 0.7731 - accuracy: 0.7949 - val_loss: 0.7942 - val_accuracy: 0.7941\n",
            "Epoch 65/100\n",
            "78/78 [==============================] - 0s 194us/sample - loss: 0.7693 - accuracy: 0.7949 - val_loss: 0.7913 - val_accuracy: 0.7941\n",
            "Epoch 66/100\n",
            "78/78 [==============================] - 0s 146us/sample - loss: 0.7656 - accuracy: 0.7949 - val_loss: 0.7885 - val_accuracy: 0.7941\n",
            "Epoch 67/100\n",
            "78/78 [==============================] - 0s 195us/sample - loss: 0.7619 - accuracy: 0.7949 - val_loss: 0.7856 - val_accuracy: 0.7941\n",
            "Epoch 68/100\n",
            "78/78 [==============================] - 0s 124us/sample - loss: 0.7582 - accuracy: 0.7949 - val_loss: 0.7828 - val_accuracy: 0.7941\n",
            "Epoch 69/100\n",
            "78/78 [==============================] - 0s 153us/sample - loss: 0.7545 - accuracy: 0.7949 - val_loss: 0.7799 - val_accuracy: 0.7941\n",
            "Epoch 70/100\n",
            "78/78 [==============================] - 0s 200us/sample - loss: 0.7509 - accuracy: 0.7949 - val_loss: 0.7771 - val_accuracy: 0.7941\n",
            "Epoch 71/100\n",
            "78/78 [==============================] - 0s 203us/sample - loss: 0.7474 - accuracy: 0.7949 - val_loss: 0.7744 - val_accuracy: 0.7941\n",
            "Epoch 72/100\n",
            "78/78 [==============================] - 0s 161us/sample - loss: 0.7438 - accuracy: 0.7949 - val_loss: 0.7716 - val_accuracy: 0.7941\n",
            "Epoch 73/100\n",
            "78/78 [==============================] - 0s 146us/sample - loss: 0.7403 - accuracy: 0.8077 - val_loss: 0.7689 - val_accuracy: 0.7941\n",
            "Epoch 74/100\n",
            "78/78 [==============================] - 0s 146us/sample - loss: 0.7368 - accuracy: 0.8077 - val_loss: 0.7661 - val_accuracy: 0.7941\n",
            "Epoch 75/100\n",
            "78/78 [==============================] - 0s 167us/sample - loss: 0.7334 - accuracy: 0.8077 - val_loss: 0.7634 - val_accuracy: 0.7941\n",
            "Epoch 76/100\n",
            "78/78 [==============================] - 0s 194us/sample - loss: 0.7300 - accuracy: 0.8077 - val_loss: 0.7607 - val_accuracy: 0.7941\n",
            "Epoch 77/100\n",
            "78/78 [==============================] - 0s 174us/sample - loss: 0.7266 - accuracy: 0.8077 - val_loss: 0.7581 - val_accuracy: 0.7941\n",
            "Epoch 78/100\n",
            "78/78 [==============================] - 0s 184us/sample - loss: 0.7232 - accuracy: 0.8077 - val_loss: 0.7554 - val_accuracy: 0.7941\n",
            "Epoch 79/100\n",
            "78/78 [==============================] - 0s 175us/sample - loss: 0.7199 - accuracy: 0.8077 - val_loss: 0.7528 - val_accuracy: 0.7941\n",
            "Epoch 80/100\n",
            "78/78 [==============================] - 0s 190us/sample - loss: 0.7166 - accuracy: 0.8077 - val_loss: 0.7502 - val_accuracy: 0.7941\n",
            "Epoch 81/100\n",
            "78/78 [==============================] - 0s 210us/sample - loss: 0.7134 - accuracy: 0.8077 - val_loss: 0.7476 - val_accuracy: 0.7941\n",
            "Epoch 82/100\n",
            "78/78 [==============================] - 0s 143us/sample - loss: 0.7102 - accuracy: 0.8077 - val_loss: 0.7450 - val_accuracy: 0.7941\n",
            "Epoch 83/100\n",
            "78/78 [==============================] - 0s 118us/sample - loss: 0.7070 - accuracy: 0.8077 - val_loss: 0.7425 - val_accuracy: 0.7941\n",
            "Epoch 84/100\n",
            "78/78 [==============================] - 0s 192us/sample - loss: 0.7038 - accuracy: 0.8077 - val_loss: 0.7399 - val_accuracy: 0.7941\n",
            "Epoch 85/100\n",
            "78/78 [==============================] - 0s 173us/sample - loss: 0.7007 - accuracy: 0.8077 - val_loss: 0.7374 - val_accuracy: 0.7941\n",
            "Epoch 86/100\n",
            "78/78 [==============================] - 0s 224us/sample - loss: 0.6976 - accuracy: 0.8077 - val_loss: 0.7349 - val_accuracy: 0.7941\n",
            "Epoch 87/100\n",
            "78/78 [==============================] - 0s 152us/sample - loss: 0.6945 - accuracy: 0.8077 - val_loss: 0.7325 - val_accuracy: 0.7941\n",
            "Epoch 88/100\n",
            "78/78 [==============================] - 0s 135us/sample - loss: 0.6914 - accuracy: 0.8077 - val_loss: 0.7300 - val_accuracy: 0.7941\n",
            "Epoch 89/100\n",
            "78/78 [==============================] - 0s 207us/sample - loss: 0.6884 - accuracy: 0.8077 - val_loss: 0.7276 - val_accuracy: 0.7941\n",
            "Epoch 90/100\n",
            "78/78 [==============================] - 0s 199us/sample - loss: 0.6855 - accuracy: 0.8077 - val_loss: 0.7251 - val_accuracy: 0.8235\n",
            "Epoch 91/100\n",
            "78/78 [==============================] - 0s 192us/sample - loss: 0.6825 - accuracy: 0.8077 - val_loss: 0.7227 - val_accuracy: 0.8235\n",
            "Epoch 92/100\n",
            "78/78 [==============================] - 0s 159us/sample - loss: 0.6796 - accuracy: 0.8077 - val_loss: 0.7204 - val_accuracy: 0.8235\n",
            "Epoch 93/100\n",
            "78/78 [==============================] - 0s 177us/sample - loss: 0.6767 - accuracy: 0.8077 - val_loss: 0.7180 - val_accuracy: 0.8235\n",
            "Epoch 94/100\n",
            "78/78 [==============================] - 0s 147us/sample - loss: 0.6738 - accuracy: 0.8077 - val_loss: 0.7157 - val_accuracy: 0.8235\n",
            "Epoch 95/100\n",
            "78/78 [==============================] - 0s 168us/sample - loss: 0.6710 - accuracy: 0.8077 - val_loss: 0.7133 - val_accuracy: 0.8235\n",
            "Epoch 96/100\n",
            "78/78 [==============================] - 0s 178us/sample - loss: 0.6682 - accuracy: 0.8205 - val_loss: 0.7110 - val_accuracy: 0.8235\n",
            "Epoch 97/100\n",
            "78/78 [==============================] - 0s 168us/sample - loss: 0.6654 - accuracy: 0.8205 - val_loss: 0.7087 - val_accuracy: 0.8235\n",
            "Epoch 98/100\n",
            "78/78 [==============================] - 0s 220us/sample - loss: 0.6626 - accuracy: 0.8205 - val_loss: 0.7065 - val_accuracy: 0.8235\n",
            "Epoch 99/100\n",
            "78/78 [==============================] - 0s 169us/sample - loss: 0.6599 - accuracy: 0.8333 - val_loss: 0.7042 - val_accuracy: 0.8235\n",
            "Epoch 100/100\n",
            "78/78 [==============================] - 0s 140us/sample - loss: 0.6572 - accuracy: 0.8333 - val_loss: 0.7020 - val_accuracy: 0.8235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdDMBfE9g3qH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.round(model.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYn80D1uiRYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "de4cd10e-c52f-4a3a-a512-a98b8e07c3f3"
      },
      "source": [
        "print(history.history['val_accuracy'])\n",
        "\n",
        "print(history.history['accuracy'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['accuracy'])\n",
        "va = pd.DataFrame(history.history['val_accuracy'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4117647, 0.4117647, 0.47058824, 0.61764705, 0.5882353, 0.44117647, 0.4117647, 0.38235295, 0.38235295, 0.38235295, 0.38235295, 0.38235295, 0.38235295, 0.38235295, 0.38235295, 0.38235295, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.4117647, 0.5, 0.5, 0.5294118, 0.5588235, 0.5588235, 0.5588235, 0.5882353, 0.64705884, 0.6764706, 0.6764706, 0.6764706, 0.6764706, 0.6764706, 0.6764706, 0.7058824, 0.7058824, 0.7058824, 0.7352941, 0.7352941, 0.7352941, 0.7352941, 0.7352941, 0.7352941, 0.7352941, 0.7352941, 0.7647059, 0.7647059, 0.7647059, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.7941176, 0.8235294, 0.8235294, 0.8235294, 0.8235294, 0.8235294, 0.8235294, 0.8235294, 0.8235294, 0.8235294, 0.8235294, 0.8235294]\n",
            "[0.32051283, 0.32051283, 0.32051283, 0.35897437, 0.525641, 0.44871795, 0.34615386, 0.33333334, 0.32051283, 0.32051283, 0.32051283, 0.32051283, 0.32051283, 0.32051283, 0.32051283, 0.32051283, 0.32051283, 0.32051283, 0.33333334, 0.33333334, 0.33333334, 0.34615386, 0.34615386, 0.34615386, 0.34615386, 0.35897437, 0.35897437, 0.35897437, 0.35897437, 0.35897437, 0.37179488, 0.41025642, 0.46153846, 0.53846157, 0.5897436, 0.64102566, 0.67948717, 0.7051282, 0.7307692, 0.74358976, 0.75641024, 0.75641024, 0.75641024, 0.75641024, 0.7692308, 0.78205127, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.7948718, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.8076923, 0.82051283, 0.82051283, 0.82051283, 0.8333333, 0.8333333]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcbf587ac50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSUgMq3m0bG7",
        "colab_type": "text"
      },
      "source": [
        "### Compare the prediction with actual label\n",
        "- Print the same row as done in the previous step but of actual labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5WbwVPyz-qQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab0a99eb-59e7-40a6-c6b1-781579ae9c34"
      },
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrTKwbgE7NFT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeoiMbH7djEv",
        "colab_type": "text"
      },
      "source": [
        "# Stock prices dataset\n",
        "The data is of tock exchange's stock listings for each trading day of 2010 to 2016.\n",
        "\n",
        "## Description\n",
        "A brief description of columns.\n",
        "- open: The opening market price of the equity symbol on the date\n",
        "- high: The highest market price of the equity symbol on the date\n",
        "- low: The lowest recorded market price of the equity symbol on the date\n",
        "- close: The closing recorded price of the equity symbol on the date\n",
        "- symbol: Symbol of the listed company\n",
        "- volume: Total traded volume of the equity symbol on the date\n",
        "- date: Date of record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSoYY2nII_UW",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, we will work on the stock prices dataset named \"prices.csv\". Task is to create a Neural Network to classify closing price for a stock based on some parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v9Ws2l6jdLa_"
      },
      "source": [
        "Firstly, let's select TensorFlow version 2.x in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "407SiobOdLbL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae64663e-176a-4262-908d-b72852ad67a4"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGqq9f8VdLba",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_88voqAH-O6J",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRHCeJqP-evf",
        "colab_type": "text"
      },
      "source": [
        "### Load the data\n",
        "- load the csv file and read it using pandas\n",
        "- file name is prices.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKVH5v7r-RmC",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "7e60bb0d-41d1-4287-aaf1-988410a5079e"
      },
      "source": [
        "# run this cell to upload file using GUI if you are using google colab\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eff2afb5-9cec-47db-aa01-fcdea67599f3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-eff2afb5-9cec-47db-aa01-fcdea67599f3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving prices.csv to prices.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-9faa9e19a23d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 72\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr4YcffYd1FQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "86c154dc-cdb6-4525-a4e4-e7b660003a7f"
      },
      "source": [
        "# run this cell to to mount the google drive if you are using google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/MyDrive/Colab Notebooks/\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-194bcbfa9413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmountpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not contain a space.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not contain a space."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI6yNBucpWHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2aa097d5-7871-4f70-dc18-2fd85b9aca5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gDC6cSW_FSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pandas \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "prices = pd.read_csv(\"/content/prices.csv\", sep=',')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlLKVPVH_BCT",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZxoGynuBeO4t"
      },
      "source": [
        "### Drop null\n",
        "- Drop null values if any"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yuwJJIeeUaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ac805671-573b-4d1f-d762-ae6d03cb2c0c"
      },
      "source": [
        "prices.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date symbol        open  ...         low        high     volume\n",
              "0  2016-01-05 00:00:00   WLTW  123.430000  ...  122.309998  126.250000  2163600.0\n",
              "1  2016-01-06 00:00:00   WLTW  125.239998  ...  119.940002  125.540001  2386400.0\n",
              "2  2016-01-07 00:00:00   WLTW  116.379997  ...  114.930000  119.739998  2489500.0\n",
              "3  2016-01-08 00:00:00   WLTW  115.480003  ...  113.500000  117.440002  2006300.0\n",
              "4  2016-01-11 00:00:00   WLTW  117.010002  ...  114.089996  117.330002  1408600.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBXX-Q3_rLZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b7aed8d8-ad88-42b8-d4cb-74078a33865a"
      },
      "source": [
        "prices.isnull().sum()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date      0\n",
              "symbol    0\n",
              "open      0\n",
              "close     0\n",
              "low       0\n",
              "high      0\n",
              "volume    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAbQ4yhNqsXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd779683-316b-4b8f-be10-69ed5efa392c"
      },
      "source": [
        "prices.shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(515035, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J4BlzVA_gZd",
        "colab_type": "text"
      },
      "source": [
        "### Drop columnns\n",
        "- Now, we don't need \"date\", \"volume\" and \"symbol\" column\n",
        "- drop \"date\", \"volume\" and \"symbol\" column from the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKEK8aEE_Csx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Drop columnns\n",
        "prices.drop(['date','volume','symbol'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTPhO6v-AiZt",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsZXmF3NAkna",
        "colab_type": "text"
      },
      "source": [
        "### Print the dataframe\n",
        "- print the modified dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKs04iIHAjxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6992d663-3fbc-4c84-b1dd-ef4590bfc96d"
      },
      "source": [
        "prices.head()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high\n",
              "0  123.430000  125.839996  122.309998  126.250000\n",
              "1  125.239998  119.980003  119.940002  125.540001\n",
              "2  116.379997  114.949997  114.930000  119.739998\n",
              "3  115.480003  116.620003  113.500000  117.440002\n",
              "4  117.010002  114.970001  114.089996  117.330002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C8u_jlbABTip"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- Let's separate labels and features now. We are going to predict the value for \"close\" column so that will be our label. Our features will be \"open\", \"low\", \"high\"\n",
        "- Take \"open\" \"low\", \"high\" columns as features\n",
        "- Take \"close\" column as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQjCMzUXBJbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = prices[['close']]\n",
        "X = prices[['open','low','high']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vGtnapgBIJm",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pZAKdJ5gcrm",
        "colab_type": "text"
      },
      "source": [
        "### Create train and test sets\n",
        "- Split the data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KalRqA6Rgqsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.3, random_state=0) #70/30 split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTAKzlxZBz0z",
        "colab_type": "text"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7BU2qxEg0Ki",
        "colab_type": "text"
      },
      "source": [
        "### Scaling\n",
        "- Scale the data (features only)\n",
        "- Use StandarScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcO8SlhPhBkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import `StandardScaler` from `sklearn.preprocessing`\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define the scaler \n",
        "scaler = StandardScaler().fit(x_train)\n",
        "\n",
        "# Scale the train set\n",
        "x_train = scaler.transform(x_train)\n",
        "\n",
        "# Scale the test set\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3TWpN0nVTpUx"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sj0LYNkhR-L",
        "colab_type": "text"
      },
      "source": [
        "### Convert data to NumPy array\n",
        "- Convert features and labels to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6mIfuTxhbTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = np.asarray(y_test)\n",
        "y_train = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "x_train = np.asarray(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbESkpe7hiVk",
        "colab_type": "text"
      },
      "source": [
        "### Reshape features\n",
        "- Reshape the features to make it suitable for input in the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ZG_CWthpTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_train.shape[0]\n",
        "#x_train.shape[1]\n",
        "#x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "#y_train = y_train.reshape(x_train.shape[0],x_train.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A2q6O-42Bkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db95e715-2251-4353-a4fb-8413348a458e"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(360524, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmXUGc2oTspa"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl2M9whFh6mh",
        "colab_type": "text"
      },
      "source": [
        "### Define Model\n",
        "- Initialize a Sequential model\n",
        "- Add a Flatten layer\n",
        "- Add a Dense layer with one neuron as output\n",
        "  - add 'linear' as activation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkiBpORmiegL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "#from keras.layers.advanced_activations import linear\n",
        "\n",
        "# define the model architecture\n",
        "\n",
        "# Initialize the constructor\n",
        "model = Sequential([Flatten(), Dense (1,activation= 'linear')])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8a0wr94aTyjg"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEaXX0ijzA__",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNZPb5lKioX0",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "- Compile the model\n",
        "- Use \"sgd\" optimizer\n",
        "- for calculating loss, use mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEQUP3VaiuT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd'\n",
        "              )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbBpnOtfT0wd"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9o45OHdjDhA",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "- epochs: 50\n",
        "- batch size: 128\n",
        "- specify validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y6tA30XjOH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59903c7c-1287-4dad-a70c-9671c4b1782e"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "#model.fit(x_train, y_train, epochs=epochs)\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.3, verbose=True)\n",
        "#loss,accuracy  = model.evaluate(x_test, y_test, verbose=False)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 252366 samples, validate on 108158 samples\n",
            "Epoch 1/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6766 - val_loss: 0.6722\n",
            "Epoch 2/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6740 - val_loss: 0.6686\n",
            "Epoch 3/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6738 - val_loss: 0.6622\n",
            "Epoch 4/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6709 - val_loss: 0.6694\n",
            "Epoch 5/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6683 - val_loss: 0.6683\n",
            "Epoch 6/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6678 - val_loss: 0.6669\n",
            "Epoch 7/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6644 - val_loss: 0.6628\n",
            "Epoch 8/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6626 - val_loss: 0.6526\n",
            "Epoch 9/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6612 - val_loss: 0.6840\n",
            "Epoch 10/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6616 - val_loss: 0.6505\n",
            "Epoch 11/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6553 - val_loss: 0.6515\n",
            "Epoch 12/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6561 - val_loss: 0.6494\n",
            "Epoch 13/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6551 - val_loss: 0.6489\n",
            "Epoch 14/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6522 - val_loss: 0.6499\n",
            "Epoch 15/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6508 - val_loss: 0.6421\n",
            "Epoch 16/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6489 - val_loss: 0.6392\n",
            "Epoch 17/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6459 - val_loss: 0.6413\n",
            "Epoch 18/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6443 - val_loss: 0.6348\n",
            "Epoch 19/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6426 - val_loss: 0.6351\n",
            "Epoch 20/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6425 - val_loss: 0.6317\n",
            "Epoch 21/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6407 - val_loss: 0.6384\n",
            "Epoch 22/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6387 - val_loss: 0.6390\n",
            "Epoch 23/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6366 - val_loss: 0.6300\n",
            "Epoch 24/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6351 - val_loss: 0.6247\n",
            "Epoch 25/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6340 - val_loss: 0.6226\n",
            "Epoch 26/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6316 - val_loss: 0.6262\n",
            "Epoch 27/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6294 - val_loss: 0.6201\n",
            "Epoch 28/50\n",
            "252366/252366 [==============================] - 4s 14us/sample - loss: 0.6281 - val_loss: 0.6178\n",
            "Epoch 29/50\n",
            "252366/252366 [==============================] - 4s 14us/sample - loss: 0.6254 - val_loss: 0.6240\n",
            "Epoch 30/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6239 - val_loss: 0.6165\n",
            "Epoch 31/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6221 - val_loss: 0.6132\n",
            "Epoch 32/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6218 - val_loss: 0.6203\n",
            "Epoch 33/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6194 - val_loss: 0.6871\n",
            "Epoch 34/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6174 - val_loss: 0.6114\n",
            "Epoch 35/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6161 - val_loss: 0.6202\n",
            "Epoch 36/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6141 - val_loss: 0.6090\n",
            "Epoch 37/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6130 - val_loss: 0.6033\n",
            "Epoch 38/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6107 - val_loss: 0.6071\n",
            "Epoch 39/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6093 - val_loss: 0.6006\n",
            "Epoch 40/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6083 - val_loss: 0.6000\n",
            "Epoch 41/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6068 - val_loss: 0.6090\n",
            "Epoch 42/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6040 - val_loss: 0.6020\n",
            "Epoch 43/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6025 - val_loss: 0.6004\n",
            "Epoch 44/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.6017 - val_loss: 0.5986\n",
            "Epoch 45/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6005 - val_loss: 0.6067\n",
            "Epoch 46/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.6002 - val_loss: 0.5896\n",
            "Epoch 47/50\n",
            "252366/252366 [==============================] - 3s 14us/sample - loss: 0.5973 - val_loss: 0.6087\n",
            "Epoch 48/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.5955 - val_loss: 0.5899\n",
            "Epoch 49/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.5946 - val_loss: 0.5946\n",
            "Epoch 50/50\n",
            "252366/252366 [==============================] - 3s 13us/sample - loss: 0.5918 - val_loss: 0.5844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW4SEP8kT2ls"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJDoix_7JU61",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "- Evaluate the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdH8pYBIjHGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,accuracy  = model.evaluate(x_test, y_test, verbose=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUpDD74Xjh01",
        "colab_type": "text"
      },
      "source": [
        "### Manual predictions\n",
        "- Test the predictions on manual inputs\n",
        "- We have scaled out training data, so we need to transform our custom inputs using the object of the scaler\n",
        "- Example of manual input: [123.430000,\t122.30999, 116.250000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvuH-c31lLiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_record = [123.430000, 122.30999, 116.250000]\n",
        "new_record = scaler.transform([new_record])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSiMhJPpk3GO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "295e86f3-da9f-4a65-a7e4-25e3ea643fbd"
      },
      "source": [
        "y_predict = model.predict(new_record)\n",
        "y_predict"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[119.912865]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    }
  ]
}